{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSbEXr5xQ_bl",
        "outputId": "c4e46dfb-1f7b-41e5-8ec7-eec43cb4a2f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RY21Bbjyk0h2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(r\"/content/DSA_features.csv\")"
      ],
      "metadata": {
        "id": "K-iJQOaxON75"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "FFFqSa1COVus",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "393a9f5b-dc16-4a83-a21a-dad3378cc2a0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
              "0        7.975714      8.1605      7.6823    0.014395    0.119981   \n",
              "1        7.978250      8.1763      7.8472    0.007551    0.086896   \n",
              "2        7.970894      8.0860      7.8470    0.003092    0.055603   \n",
              "3        7.938412      8.1083      7.6901    0.003763    0.061343   \n",
              "4        7.908930      8.1305      7.8322    0.001741    0.041731   \n",
              "...           ...         ...         ...         ...         ...   \n",
              "9115     8.280854     34.1980     -2.9038   28.080803    5.299132   \n",
              "9116     9.591118     51.6970     -3.4129   35.722025    5.976791   \n",
              "9117     9.599113     27.9300     -1.0765   48.850886    6.989341   \n",
              "9118     9.692482     72.7820     -2.6734   59.378336    7.705734   \n",
              "9119     9.380641     45.0090     -3.5938   40.459334    6.360765   \n",
              "\n",
              "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
              "0       -0.023319     1.083150      1.1832     0.99744    0.002208  ...   \n",
              "1        0.552416     1.140865      1.2129     1.05810    0.000784  ...   \n",
              "2        0.100538     1.140962      1.2128     1.07960    0.000508  ...   \n",
              "3       -0.231914     1.165260      1.3170     1.07870    0.002173  ...   \n",
              "4        2.042285     1.187504      1.2574     1.09450    0.000662  ...   \n",
              "...           ...          ...         ...         ...         ...  ...   \n",
              "9115     1.350075    -1.491537     11.2240   -11.65100   14.670334  ...   \n",
              "9116     2.981144     0.086304      6.9951   -11.76400    5.329897  ...   \n",
              "9117     0.449237    -0.728367      3.7801    -8.36910    5.683022  ...   \n",
              "9118     4.491114    -0.582724      6.1216    -8.85710    4.162963  ...   \n",
              "9119     1.688626    -0.266325      5.8603    -6.91970    4.017098  ...   \n",
              "\n",
              "      LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  \\\n",
              "0        0.000792      0.177075     -0.057119    -0.054963    -0.059241   \n",
              "1        0.000860     -0.286918     -0.057268    -0.054945    -0.059589   \n",
              "2        0.000762     -0.134430     -0.057068    -0.054711    -0.059065   \n",
              "3        0.000735      0.021485     -0.056422    -0.053670    -0.058310   \n",
              "4        0.000824     -0.148229     -0.055801    -0.053313    -0.057815   \n",
              "...           ...           ...           ...          ...          ...   \n",
              "9115     0.200829     -0.040701      0.297666     0.708480    -0.117430   \n",
              "9116     0.148745     -0.266377      0.224716     0.554670    -0.250950   \n",
              "9117     0.310748     -0.009505     -0.237786     0.088854    -0.477260   \n",
              "9118     0.156493      0.050624      0.533023     0.677800     0.055941   \n",
              "9119     0.229154     -0.342228      0.491919     0.707920     0.251280   \n",
              "\n",
              "       LL_zmag_var  LL_zmag_std  LL_zmag_skew    activity  people  \n",
              "0     6.778722e-07     0.000823      0.036729     sitting      p1  \n",
              "1     7.032302e-07     0.000839      0.347471     sitting      p1  \n",
              "2     6.268222e-07     0.000792      0.045579     sitting      p1  \n",
              "3     8.011245e-07     0.000895      0.240690     sitting      p1  \n",
              "4     6.853423e-07     0.000828      0.258429     sitting      p1  \n",
              "...            ...          ...           ...         ...     ...  \n",
              "9115  4.135451e-02     0.203358     -0.310022  basketBall      p8  \n",
              "9116  3.355704e-02     0.183186     -0.736410  basketBall      p8  \n",
              "9117  2.026107e-02     0.142341      0.668438  basketBall      p8  \n",
              "9118  1.356379e-02     0.116464     -1.482489  basketBall      p8  \n",
              "9119  9.358254e-03     0.096738     -0.223302  basketBall      p8  \n",
              "\n",
              "[9120 rows x 272 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-297e8344-1dc6-46d8-8f54-f1985b841b52\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T_xacc_mean</th>\n",
              "      <th>T_xacc_max</th>\n",
              "      <th>T_xacc_min</th>\n",
              "      <th>T_xacc_var</th>\n",
              "      <th>T_xacc_std</th>\n",
              "      <th>T_xacc_skew</th>\n",
              "      <th>T_yacc_mean</th>\n",
              "      <th>T_yacc_max</th>\n",
              "      <th>T_yacc_min</th>\n",
              "      <th>T_yacc_var</th>\n",
              "      <th>...</th>\n",
              "      <th>LL_ymag_std</th>\n",
              "      <th>LL_ymag_skew</th>\n",
              "      <th>LL_zmag_mean</th>\n",
              "      <th>LL_zmag_max</th>\n",
              "      <th>LL_zmag_min</th>\n",
              "      <th>LL_zmag_var</th>\n",
              "      <th>LL_zmag_std</th>\n",
              "      <th>LL_zmag_skew</th>\n",
              "      <th>activity</th>\n",
              "      <th>people</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.975714</td>\n",
              "      <td>8.1605</td>\n",
              "      <td>7.6823</td>\n",
              "      <td>0.014395</td>\n",
              "      <td>0.119981</td>\n",
              "      <td>-0.023319</td>\n",
              "      <td>1.083150</td>\n",
              "      <td>1.1832</td>\n",
              "      <td>0.99744</td>\n",
              "      <td>0.002208</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000792</td>\n",
              "      <td>0.177075</td>\n",
              "      <td>-0.057119</td>\n",
              "      <td>-0.054963</td>\n",
              "      <td>-0.059241</td>\n",
              "      <td>6.778722e-07</td>\n",
              "      <td>0.000823</td>\n",
              "      <td>0.036729</td>\n",
              "      <td>sitting</td>\n",
              "      <td>p1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.978250</td>\n",
              "      <td>8.1763</td>\n",
              "      <td>7.8472</td>\n",
              "      <td>0.007551</td>\n",
              "      <td>0.086896</td>\n",
              "      <td>0.552416</td>\n",
              "      <td>1.140865</td>\n",
              "      <td>1.2129</td>\n",
              "      <td>1.05810</td>\n",
              "      <td>0.000784</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000860</td>\n",
              "      <td>-0.286918</td>\n",
              "      <td>-0.057268</td>\n",
              "      <td>-0.054945</td>\n",
              "      <td>-0.059589</td>\n",
              "      <td>7.032302e-07</td>\n",
              "      <td>0.000839</td>\n",
              "      <td>0.347471</td>\n",
              "      <td>sitting</td>\n",
              "      <td>p1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.970894</td>\n",
              "      <td>8.0860</td>\n",
              "      <td>7.8470</td>\n",
              "      <td>0.003092</td>\n",
              "      <td>0.055603</td>\n",
              "      <td>0.100538</td>\n",
              "      <td>1.140962</td>\n",
              "      <td>1.2128</td>\n",
              "      <td>1.07960</td>\n",
              "      <td>0.000508</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000762</td>\n",
              "      <td>-0.134430</td>\n",
              "      <td>-0.057068</td>\n",
              "      <td>-0.054711</td>\n",
              "      <td>-0.059065</td>\n",
              "      <td>6.268222e-07</td>\n",
              "      <td>0.000792</td>\n",
              "      <td>0.045579</td>\n",
              "      <td>sitting</td>\n",
              "      <td>p1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.938412</td>\n",
              "      <td>8.1083</td>\n",
              "      <td>7.6901</td>\n",
              "      <td>0.003763</td>\n",
              "      <td>0.061343</td>\n",
              "      <td>-0.231914</td>\n",
              "      <td>1.165260</td>\n",
              "      <td>1.3170</td>\n",
              "      <td>1.07870</td>\n",
              "      <td>0.002173</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000735</td>\n",
              "      <td>0.021485</td>\n",
              "      <td>-0.056422</td>\n",
              "      <td>-0.053670</td>\n",
              "      <td>-0.058310</td>\n",
              "      <td>8.011245e-07</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>0.240690</td>\n",
              "      <td>sitting</td>\n",
              "      <td>p1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.908930</td>\n",
              "      <td>8.1305</td>\n",
              "      <td>7.8322</td>\n",
              "      <td>0.001741</td>\n",
              "      <td>0.041731</td>\n",
              "      <td>2.042285</td>\n",
              "      <td>1.187504</td>\n",
              "      <td>1.2574</td>\n",
              "      <td>1.09450</td>\n",
              "      <td>0.000662</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000824</td>\n",
              "      <td>-0.148229</td>\n",
              "      <td>-0.055801</td>\n",
              "      <td>-0.053313</td>\n",
              "      <td>-0.057815</td>\n",
              "      <td>6.853423e-07</td>\n",
              "      <td>0.000828</td>\n",
              "      <td>0.258429</td>\n",
              "      <td>sitting</td>\n",
              "      <td>p1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9115</th>\n",
              "      <td>8.280854</td>\n",
              "      <td>34.1980</td>\n",
              "      <td>-2.9038</td>\n",
              "      <td>28.080803</td>\n",
              "      <td>5.299132</td>\n",
              "      <td>1.350075</td>\n",
              "      <td>-1.491537</td>\n",
              "      <td>11.2240</td>\n",
              "      <td>-11.65100</td>\n",
              "      <td>14.670334</td>\n",
              "      <td>...</td>\n",
              "      <td>0.200829</td>\n",
              "      <td>-0.040701</td>\n",
              "      <td>0.297666</td>\n",
              "      <td>0.708480</td>\n",
              "      <td>-0.117430</td>\n",
              "      <td>4.135451e-02</td>\n",
              "      <td>0.203358</td>\n",
              "      <td>-0.310022</td>\n",
              "      <td>basketBall</td>\n",
              "      <td>p8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9116</th>\n",
              "      <td>9.591118</td>\n",
              "      <td>51.6970</td>\n",
              "      <td>-3.4129</td>\n",
              "      <td>35.722025</td>\n",
              "      <td>5.976791</td>\n",
              "      <td>2.981144</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>6.9951</td>\n",
              "      <td>-11.76400</td>\n",
              "      <td>5.329897</td>\n",
              "      <td>...</td>\n",
              "      <td>0.148745</td>\n",
              "      <td>-0.266377</td>\n",
              "      <td>0.224716</td>\n",
              "      <td>0.554670</td>\n",
              "      <td>-0.250950</td>\n",
              "      <td>3.355704e-02</td>\n",
              "      <td>0.183186</td>\n",
              "      <td>-0.736410</td>\n",
              "      <td>basketBall</td>\n",
              "      <td>p8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9117</th>\n",
              "      <td>9.599113</td>\n",
              "      <td>27.9300</td>\n",
              "      <td>-1.0765</td>\n",
              "      <td>48.850886</td>\n",
              "      <td>6.989341</td>\n",
              "      <td>0.449237</td>\n",
              "      <td>-0.728367</td>\n",
              "      <td>3.7801</td>\n",
              "      <td>-8.36910</td>\n",
              "      <td>5.683022</td>\n",
              "      <td>...</td>\n",
              "      <td>0.310748</td>\n",
              "      <td>-0.009505</td>\n",
              "      <td>-0.237786</td>\n",
              "      <td>0.088854</td>\n",
              "      <td>-0.477260</td>\n",
              "      <td>2.026107e-02</td>\n",
              "      <td>0.142341</td>\n",
              "      <td>0.668438</td>\n",
              "      <td>basketBall</td>\n",
              "      <td>p8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9118</th>\n",
              "      <td>9.692482</td>\n",
              "      <td>72.7820</td>\n",
              "      <td>-2.6734</td>\n",
              "      <td>59.378336</td>\n",
              "      <td>7.705734</td>\n",
              "      <td>4.491114</td>\n",
              "      <td>-0.582724</td>\n",
              "      <td>6.1216</td>\n",
              "      <td>-8.85710</td>\n",
              "      <td>4.162963</td>\n",
              "      <td>...</td>\n",
              "      <td>0.156493</td>\n",
              "      <td>0.050624</td>\n",
              "      <td>0.533023</td>\n",
              "      <td>0.677800</td>\n",
              "      <td>0.055941</td>\n",
              "      <td>1.356379e-02</td>\n",
              "      <td>0.116464</td>\n",
              "      <td>-1.482489</td>\n",
              "      <td>basketBall</td>\n",
              "      <td>p8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9119</th>\n",
              "      <td>9.380641</td>\n",
              "      <td>45.0090</td>\n",
              "      <td>-3.5938</td>\n",
              "      <td>40.459334</td>\n",
              "      <td>6.360765</td>\n",
              "      <td>1.688626</td>\n",
              "      <td>-0.266325</td>\n",
              "      <td>5.8603</td>\n",
              "      <td>-6.91970</td>\n",
              "      <td>4.017098</td>\n",
              "      <td>...</td>\n",
              "      <td>0.229154</td>\n",
              "      <td>-0.342228</td>\n",
              "      <td>0.491919</td>\n",
              "      <td>0.707920</td>\n",
              "      <td>0.251280</td>\n",
              "      <td>9.358254e-03</td>\n",
              "      <td>0.096738</td>\n",
              "      <td>-0.223302</td>\n",
              "      <td>basketBall</td>\n",
              "      <td>p8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9120 rows × 272 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-297e8344-1dc6-46d8-8f54-f1985b841b52')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-297e8344-1dc6-46d8-8f54-f1985b841b52 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-297e8344-1dc6-46d8-8f54-f1985b841b52');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-98260d66-d64b-47f4-9148-2b24eb01cfc2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-98260d66-d64b-47f4-9148-2b24eb01cfc2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-98260d66-d64b-47f4-9148-2b24eb01cfc2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f32f49f9-ca1d-4ad2-b304-c2a9636aa03a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f32f49f9-ca1d-4ad2-b304-c2a9636aa03a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= df.drop(columns=['people'])"
      ],
      "metadata": {
        "id": "4D7VD5UyOZrt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# LabelEncoder 객체 생성\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# activity 열을 Label Encoding\n",
        "df['activity'] = label_encoder.fit_transform(df['activity'])\n",
        "\n",
        "# 변환된 activity 값 확인\n",
        "print(df['activity'].value_counts())"
      ],
      "metadata": {
        "id": "55KvjULXOsSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc5b4a5c-7a3b-483f-93a1-c6cecdfa15f9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "activity\n",
            "12    480\n",
            "13    480\n",
            "7     480\n",
            "8     480\n",
            "0     480\n",
            "5     480\n",
            "14    480\n",
            "9     480\n",
            "16    480\n",
            "17    480\n",
            "18    480\n",
            "11    480\n",
            "15    480\n",
            "2     480\n",
            "3     480\n",
            "4     480\n",
            "10    480\n",
            "6     480\n",
            "1     480\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "rL_aYNMGOyG4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "1e7b6b31-4c14-44c1-bd31-2700339cd91a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
              "0        7.975714      8.1605      7.6823    0.014395    0.119981   \n",
              "1        7.978250      8.1763      7.8472    0.007551    0.086896   \n",
              "2        7.970894      8.0860      7.8470    0.003092    0.055603   \n",
              "3        7.938412      8.1083      7.6901    0.003763    0.061343   \n",
              "4        7.908930      8.1305      7.8322    0.001741    0.041731   \n",
              "...           ...         ...         ...         ...         ...   \n",
              "9115     8.280854     34.1980     -2.9038   28.080803    5.299132   \n",
              "9116     9.591118     51.6970     -3.4129   35.722025    5.976791   \n",
              "9117     9.599113     27.9300     -1.0765   48.850886    6.989341   \n",
              "9118     9.692482     72.7820     -2.6734   59.378336    7.705734   \n",
              "9119     9.380641     45.0090     -3.5938   40.459334    6.360765   \n",
              "\n",
              "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
              "0       -0.023319     1.083150      1.1832     0.99744    0.002208  ...   \n",
              "1        0.552416     1.140865      1.2129     1.05810    0.000784  ...   \n",
              "2        0.100538     1.140962      1.2128     1.07960    0.000508  ...   \n",
              "3       -0.231914     1.165260      1.3170     1.07870    0.002173  ...   \n",
              "4        2.042285     1.187504      1.2574     1.09450    0.000662  ...   \n",
              "...           ...          ...         ...         ...         ...  ...   \n",
              "9115     1.350075    -1.491537     11.2240   -11.65100   14.670334  ...   \n",
              "9116     2.981144     0.086304      6.9951   -11.76400    5.329897  ...   \n",
              "9117     0.449237    -0.728367      3.7801    -8.36910    5.683022  ...   \n",
              "9118     4.491114    -0.582724      6.1216    -8.85710    4.162963  ...   \n",
              "9119     1.688626    -0.266325      5.8603    -6.91970    4.017098  ...   \n",
              "\n",
              "       LL_ymag_var  LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  \\\n",
              "0     6.267229e-07     0.000792      0.177075     -0.057119    -0.054963   \n",
              "1     7.403458e-07     0.000860     -0.286918     -0.057268    -0.054945   \n",
              "2     5.802523e-07     0.000762     -0.134430     -0.057068    -0.054711   \n",
              "3     5.398837e-07     0.000735      0.021485     -0.056422    -0.053670   \n",
              "4     6.787533e-07     0.000824     -0.148229     -0.055801    -0.053313   \n",
              "...            ...          ...           ...           ...          ...   \n",
              "9115  4.033226e-02     0.200829     -0.040701      0.297666     0.708480   \n",
              "9116  2.212497e-02     0.148745     -0.266377      0.224716     0.554670   \n",
              "9117  9.656444e-02     0.310748     -0.009505     -0.237786     0.088854   \n",
              "9118  2.448990e-02     0.156493      0.050624      0.533023     0.677800   \n",
              "9119  5.251176e-02     0.229154     -0.342228      0.491919     0.707920   \n",
              "\n",
              "      LL_zmag_min   LL_zmag_var  LL_zmag_std  LL_zmag_skew  activity  \n",
              "0       -0.059241  6.778722e-07     0.000823      0.036729        12  \n",
              "1       -0.059589  7.032302e-07     0.000839      0.347471        12  \n",
              "2       -0.059065  6.268222e-07     0.000792      0.045579        12  \n",
              "3       -0.058310  8.011245e-07     0.000895      0.240690        12  \n",
              "4       -0.057815  6.853423e-07     0.000828      0.258429        12  \n",
              "...           ...           ...          ...           ...       ...  \n",
              "9115    -0.117430  4.135451e-02     0.203358     -0.310022         1  \n",
              "9116    -0.250950  3.355704e-02     0.183186     -0.736410         1  \n",
              "9117    -0.477260  2.026107e-02     0.142341      0.668438         1  \n",
              "9118     0.055941  1.356379e-02     0.116464     -1.482489         1  \n",
              "9119     0.251280  9.358254e-03     0.096738     -0.223302         1  \n",
              "\n",
              "[9120 rows x 271 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65dfe1a9-c6e2-4e2c-8949-dcdd3ee376c0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T_xacc_mean</th>\n",
              "      <th>T_xacc_max</th>\n",
              "      <th>T_xacc_min</th>\n",
              "      <th>T_xacc_var</th>\n",
              "      <th>T_xacc_std</th>\n",
              "      <th>T_xacc_skew</th>\n",
              "      <th>T_yacc_mean</th>\n",
              "      <th>T_yacc_max</th>\n",
              "      <th>T_yacc_min</th>\n",
              "      <th>T_yacc_var</th>\n",
              "      <th>...</th>\n",
              "      <th>LL_ymag_var</th>\n",
              "      <th>LL_ymag_std</th>\n",
              "      <th>LL_ymag_skew</th>\n",
              "      <th>LL_zmag_mean</th>\n",
              "      <th>LL_zmag_max</th>\n",
              "      <th>LL_zmag_min</th>\n",
              "      <th>LL_zmag_var</th>\n",
              "      <th>LL_zmag_std</th>\n",
              "      <th>LL_zmag_skew</th>\n",
              "      <th>activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.975714</td>\n",
              "      <td>8.1605</td>\n",
              "      <td>7.6823</td>\n",
              "      <td>0.014395</td>\n",
              "      <td>0.119981</td>\n",
              "      <td>-0.023319</td>\n",
              "      <td>1.083150</td>\n",
              "      <td>1.1832</td>\n",
              "      <td>0.99744</td>\n",
              "      <td>0.002208</td>\n",
              "      <td>...</td>\n",
              "      <td>6.267229e-07</td>\n",
              "      <td>0.000792</td>\n",
              "      <td>0.177075</td>\n",
              "      <td>-0.057119</td>\n",
              "      <td>-0.054963</td>\n",
              "      <td>-0.059241</td>\n",
              "      <td>6.778722e-07</td>\n",
              "      <td>0.000823</td>\n",
              "      <td>0.036729</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.978250</td>\n",
              "      <td>8.1763</td>\n",
              "      <td>7.8472</td>\n",
              "      <td>0.007551</td>\n",
              "      <td>0.086896</td>\n",
              "      <td>0.552416</td>\n",
              "      <td>1.140865</td>\n",
              "      <td>1.2129</td>\n",
              "      <td>1.05810</td>\n",
              "      <td>0.000784</td>\n",
              "      <td>...</td>\n",
              "      <td>7.403458e-07</td>\n",
              "      <td>0.000860</td>\n",
              "      <td>-0.286918</td>\n",
              "      <td>-0.057268</td>\n",
              "      <td>-0.054945</td>\n",
              "      <td>-0.059589</td>\n",
              "      <td>7.032302e-07</td>\n",
              "      <td>0.000839</td>\n",
              "      <td>0.347471</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.970894</td>\n",
              "      <td>8.0860</td>\n",
              "      <td>7.8470</td>\n",
              "      <td>0.003092</td>\n",
              "      <td>0.055603</td>\n",
              "      <td>0.100538</td>\n",
              "      <td>1.140962</td>\n",
              "      <td>1.2128</td>\n",
              "      <td>1.07960</td>\n",
              "      <td>0.000508</td>\n",
              "      <td>...</td>\n",
              "      <td>5.802523e-07</td>\n",
              "      <td>0.000762</td>\n",
              "      <td>-0.134430</td>\n",
              "      <td>-0.057068</td>\n",
              "      <td>-0.054711</td>\n",
              "      <td>-0.059065</td>\n",
              "      <td>6.268222e-07</td>\n",
              "      <td>0.000792</td>\n",
              "      <td>0.045579</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.938412</td>\n",
              "      <td>8.1083</td>\n",
              "      <td>7.6901</td>\n",
              "      <td>0.003763</td>\n",
              "      <td>0.061343</td>\n",
              "      <td>-0.231914</td>\n",
              "      <td>1.165260</td>\n",
              "      <td>1.3170</td>\n",
              "      <td>1.07870</td>\n",
              "      <td>0.002173</td>\n",
              "      <td>...</td>\n",
              "      <td>5.398837e-07</td>\n",
              "      <td>0.000735</td>\n",
              "      <td>0.021485</td>\n",
              "      <td>-0.056422</td>\n",
              "      <td>-0.053670</td>\n",
              "      <td>-0.058310</td>\n",
              "      <td>8.011245e-07</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>0.240690</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.908930</td>\n",
              "      <td>8.1305</td>\n",
              "      <td>7.8322</td>\n",
              "      <td>0.001741</td>\n",
              "      <td>0.041731</td>\n",
              "      <td>2.042285</td>\n",
              "      <td>1.187504</td>\n",
              "      <td>1.2574</td>\n",
              "      <td>1.09450</td>\n",
              "      <td>0.000662</td>\n",
              "      <td>...</td>\n",
              "      <td>6.787533e-07</td>\n",
              "      <td>0.000824</td>\n",
              "      <td>-0.148229</td>\n",
              "      <td>-0.055801</td>\n",
              "      <td>-0.053313</td>\n",
              "      <td>-0.057815</td>\n",
              "      <td>6.853423e-07</td>\n",
              "      <td>0.000828</td>\n",
              "      <td>0.258429</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9115</th>\n",
              "      <td>8.280854</td>\n",
              "      <td>34.1980</td>\n",
              "      <td>-2.9038</td>\n",
              "      <td>28.080803</td>\n",
              "      <td>5.299132</td>\n",
              "      <td>1.350075</td>\n",
              "      <td>-1.491537</td>\n",
              "      <td>11.2240</td>\n",
              "      <td>-11.65100</td>\n",
              "      <td>14.670334</td>\n",
              "      <td>...</td>\n",
              "      <td>4.033226e-02</td>\n",
              "      <td>0.200829</td>\n",
              "      <td>-0.040701</td>\n",
              "      <td>0.297666</td>\n",
              "      <td>0.708480</td>\n",
              "      <td>-0.117430</td>\n",
              "      <td>4.135451e-02</td>\n",
              "      <td>0.203358</td>\n",
              "      <td>-0.310022</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9116</th>\n",
              "      <td>9.591118</td>\n",
              "      <td>51.6970</td>\n",
              "      <td>-3.4129</td>\n",
              "      <td>35.722025</td>\n",
              "      <td>5.976791</td>\n",
              "      <td>2.981144</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>6.9951</td>\n",
              "      <td>-11.76400</td>\n",
              "      <td>5.329897</td>\n",
              "      <td>...</td>\n",
              "      <td>2.212497e-02</td>\n",
              "      <td>0.148745</td>\n",
              "      <td>-0.266377</td>\n",
              "      <td>0.224716</td>\n",
              "      <td>0.554670</td>\n",
              "      <td>-0.250950</td>\n",
              "      <td>3.355704e-02</td>\n",
              "      <td>0.183186</td>\n",
              "      <td>-0.736410</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9117</th>\n",
              "      <td>9.599113</td>\n",
              "      <td>27.9300</td>\n",
              "      <td>-1.0765</td>\n",
              "      <td>48.850886</td>\n",
              "      <td>6.989341</td>\n",
              "      <td>0.449237</td>\n",
              "      <td>-0.728367</td>\n",
              "      <td>3.7801</td>\n",
              "      <td>-8.36910</td>\n",
              "      <td>5.683022</td>\n",
              "      <td>...</td>\n",
              "      <td>9.656444e-02</td>\n",
              "      <td>0.310748</td>\n",
              "      <td>-0.009505</td>\n",
              "      <td>-0.237786</td>\n",
              "      <td>0.088854</td>\n",
              "      <td>-0.477260</td>\n",
              "      <td>2.026107e-02</td>\n",
              "      <td>0.142341</td>\n",
              "      <td>0.668438</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9118</th>\n",
              "      <td>9.692482</td>\n",
              "      <td>72.7820</td>\n",
              "      <td>-2.6734</td>\n",
              "      <td>59.378336</td>\n",
              "      <td>7.705734</td>\n",
              "      <td>4.491114</td>\n",
              "      <td>-0.582724</td>\n",
              "      <td>6.1216</td>\n",
              "      <td>-8.85710</td>\n",
              "      <td>4.162963</td>\n",
              "      <td>...</td>\n",
              "      <td>2.448990e-02</td>\n",
              "      <td>0.156493</td>\n",
              "      <td>0.050624</td>\n",
              "      <td>0.533023</td>\n",
              "      <td>0.677800</td>\n",
              "      <td>0.055941</td>\n",
              "      <td>1.356379e-02</td>\n",
              "      <td>0.116464</td>\n",
              "      <td>-1.482489</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9119</th>\n",
              "      <td>9.380641</td>\n",
              "      <td>45.0090</td>\n",
              "      <td>-3.5938</td>\n",
              "      <td>40.459334</td>\n",
              "      <td>6.360765</td>\n",
              "      <td>1.688626</td>\n",
              "      <td>-0.266325</td>\n",
              "      <td>5.8603</td>\n",
              "      <td>-6.91970</td>\n",
              "      <td>4.017098</td>\n",
              "      <td>...</td>\n",
              "      <td>5.251176e-02</td>\n",
              "      <td>0.229154</td>\n",
              "      <td>-0.342228</td>\n",
              "      <td>0.491919</td>\n",
              "      <td>0.707920</td>\n",
              "      <td>0.251280</td>\n",
              "      <td>9.358254e-03</td>\n",
              "      <td>0.096738</td>\n",
              "      <td>-0.223302</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9120 rows × 271 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65dfe1a9-c6e2-4e2c-8949-dcdd3ee376c0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-65dfe1a9-c6e2-4e2c-8949-dcdd3ee376c0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-65dfe1a9-c6e2-4e2c-8949-dcdd3ee376c0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9f23fdf3-f41a-46ee-acab-7d84e4335a3c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f23fdf3-f41a-46ee-acab-7d84e4335a3c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9f23fdf3-f41a-46ee-acab-7d84e4335a3c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6f3274be-32a6-4336-b05a-7888e05da379\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6f3274be-32a6-4336-b05a-7888e05da379 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 activity 별로 10개의 샘플 선택\n",
        "df_reduced = df.groupby('activity', group_keys=False).apply(lambda x: x.sample(n=100))\n",
        "\n",
        "# 결과 확인\n",
        "print(df_reduced)\n",
        "\n",
        "# 변환된 activity 값 확인\n",
        "print(df_reduced['activity'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeV88QRUaZ2y",
        "outputId": "ca80cc7b-9f10-4af1-c229-1fa9177b8bac"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
            "2368     9.667474      15.006      7.0838    3.115504    1.765079   \n",
            "2094     9.512914      14.697      6.6604    3.536184    1.880474   \n",
            "2380     9.549409      14.050      7.1000    1.909506    1.381849   \n",
            "1958     7.552157      14.464      0.0000   16.366857    4.045597   \n",
            "1927     7.584055      14.907      0.0000   16.794185    4.098071   \n",
            "...           ...         ...         ...         ...         ...   \n",
            "4997     9.709284      13.874      6.2289    4.061056    2.015206   \n",
            "5261     9.784546      15.834      4.2969   11.382438    3.373787   \n",
            "4889     9.757790      16.600      5.8296    7.705497    2.775878   \n",
            "4934     9.672468      14.705      6.2615    5.128150    2.264542   \n",
            "5155     9.412193      14.286      5.0127    6.231367    2.496271   \n",
            "\n",
            "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
            "2368     1.002266    -0.378052      3.4061     -2.7182    2.274355  ...   \n",
            "2094     1.068731    -0.007711      2.8768     -3.1167    3.184902  ...   \n",
            "2380     1.138697    -0.963162      2.3490     -2.8213    2.360805  ...   \n",
            "1958    -0.995971     0.414228      2.5006     -1.1651    1.048710  ...   \n",
            "1927    -0.947776     0.077146      2.6329     -2.4087    1.587412  ...   \n",
            "...           ...          ...         ...         ...         ...  ...   \n",
            "4997     0.576738     0.319592      3.0564     -2.0147    1.045224  ...   \n",
            "5261    -0.023248    -0.311795      2.6958     -4.0146    1.913709  ...   \n",
            "4889     0.816060     0.084013      2.3295     -2.3718    0.785923  ...   \n",
            "4934     0.685894    -0.468592      2.3863     -3.4942    2.291814  ...   \n",
            "5155    -0.124255    -0.224559      1.7696     -2.0450    0.841999  ...   \n",
            "\n",
            "      LL_ymag_var  LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  \\\n",
            "2368     0.008868     0.094170      0.043267     -0.394106    -0.250240   \n",
            "2094     0.006079     0.077968     -0.035910     -0.036212     0.070670   \n",
            "2380     0.024021     0.154986     -0.485474     -0.390649    -0.295850   \n",
            "1958     0.032307     0.179741     -0.773442     -0.173190     0.000000   \n",
            "1927     0.037765     0.194333     -0.804617     -0.130925     0.000000   \n",
            "...           ...          ...           ...           ...          ...   \n",
            "4997     0.064546     0.254059     -0.375782     -0.105379     0.050965   \n",
            "5261     0.056567     0.237838     -0.492526     -0.139364     0.064573   \n",
            "4889     0.021904     0.147999     -0.394371      0.102118     0.278870   \n",
            "4934     0.089449     0.299081     -0.188342     -0.031953     0.112670   \n",
            "5155     0.048577     0.220401     -0.257563     -0.149542    -0.035892   \n",
            "\n",
            "      LL_zmag_min  LL_zmag_var  LL_zmag_std  LL_zmag_skew  activity  \n",
            "2368    -0.638010     0.008238     0.090765     -1.197421         0  \n",
            "2094    -0.116010     0.001959     0.044255      0.531750         0  \n",
            "2380    -0.531540     0.003619     0.060162     -0.419461         0  \n",
            "1958    -0.294030     0.008461     0.091982      1.090634         0  \n",
            "1927    -0.267330     0.005681     0.075375      0.652412         0  \n",
            "...           ...          ...          ...           ...       ...  \n",
            "4997    -0.310050     0.008976     0.094743     -0.435646        18  \n",
            "5261    -0.437770     0.017042     0.130543     -0.415812        18  \n",
            "4889    -0.006691     0.006509     0.080678      0.444707        18  \n",
            "4934    -0.287480     0.011093     0.105322     -0.724257        18  \n",
            "5155    -0.277320     0.003199     0.056564     -0.265869        18  \n",
            "\n",
            "[1900 rows x 271 columns]\n",
            "activity\n",
            "0     100\n",
            "1     100\n",
            "2     100\n",
            "3     100\n",
            "4     100\n",
            "5     100\n",
            "6     100\n",
            "7     100\n",
            "8     100\n",
            "9     100\n",
            "10    100\n",
            "11    100\n",
            "12    100\n",
            "13    100\n",
            "14    100\n",
            "15    100\n",
            "16    100\n",
            "17    100\n",
            "18    100\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-24fe384fc97c>:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_reduced = df.groupby('activity', group_keys=False).apply(lambda x: x.sample(n=100))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "y_test = test_data['activity'].values\n",
        "y_train = train_data['activity'].values\n",
        "\n",
        "x_test = test_data.drop(columns=['activity']).values\n",
        "x_train = train_data.drop(columns=['activity']).values\n",
        "\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "idx = np.random.permutation(len(x_train))\n",
        "x_train = x_train[idx]\n",
        "y_train = y_train[idx]\n",
        "\n",
        "y_train[y_train == -1] = 0\n",
        "y_test[y_test == -1] = 0"
      ],
      "metadata": {
        "id": "R7GVH554OEKY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Attention and Normalization\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    return x + res"
      ],
      "metadata": {
        "id": "pD-Mh75Fl_lq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=(input_shape[0], 1))\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_last\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "wvcXeluomDr5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "model = build_model(\n",
        "    input_shape,\n",
        "    head_size=256,\n",
        "    num_heads=4,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[128],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=150,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "model.evaluate(x_test, y_test, verbose=1)"
      ],
      "metadata": {
        "id": "CW8Y2UjHmGuK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2af732fa-e722-4a4b-e5c1-7a6b5286d600"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m7,169\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │              \u001b[38;5;34m8\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m5\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "│                           │                        │                │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m7,169\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n",
              "│                           │                        │                │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │              \u001b[38;5;34m8\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m5\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_3… │\n",
              "│                           │                        │                │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m7,169\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_4… │\n",
              "│                           │                        │                │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │              \u001b[38;5;34m8\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m5\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_5… │\n",
              "│                           │                        │                │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_3    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m7,169\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_6… │\n",
              "│                           │                        │                │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │              \u001b[38;5;34m8\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m5\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_7… │\n",
              "│                           │                        │                │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │            \u001b[38;5;34m256\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)             │          \u001b[38;5;34m2,451\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "│                           │                        │                │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n",
              "│                           │                        │                │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3… │\n",
              "│                           │                        │                │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4… │\n",
              "│                           │                        │                │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5… │\n",
              "│                           │                        │                │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_3    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_6… │\n",
              "│                           │                        │                │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_7… │\n",
              "│                           │                        │                │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,451\u001b[0m (122.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,451</span> (122.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,451\u001b[0m (122.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,451</span> (122.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 326ms/step - loss: 2.9893 - sparse_categorical_accuracy: 0.0597 - val_loss: 2.9361 - val_sparse_categorical_accuracy: 0.0678\n",
            "Epoch 2/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 2.9346 - sparse_categorical_accuracy: 0.0852 - val_loss: 2.8837 - val_sparse_categorical_accuracy: 0.1116\n",
            "Epoch 3/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 2.8790 - sparse_categorical_accuracy: 0.1054 - val_loss: 2.8328 - val_sparse_categorical_accuracy: 0.1199\n",
            "Epoch 4/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 124ms/step - loss: 2.8279 - sparse_categorical_accuracy: 0.1077 - val_loss: 2.7783 - val_sparse_categorical_accuracy: 0.1178\n",
            "Epoch 5/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 2.7668 - sparse_categorical_accuracy: 0.1074 - val_loss: 2.7228 - val_sparse_categorical_accuracy: 0.1164\n",
            "Epoch 6/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 2.7191 - sparse_categorical_accuracy: 0.1049 - val_loss: 2.6723 - val_sparse_categorical_accuracy: 0.1151\n",
            "Epoch 7/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - loss: 2.6734 - sparse_categorical_accuracy: 0.1030 - val_loss: 2.6300 - val_sparse_categorical_accuracy: 0.1123\n",
            "Epoch 8/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 2.6335 - sparse_categorical_accuracy: 0.1041 - val_loss: 2.5960 - val_sparse_categorical_accuracy: 0.1123\n",
            "Epoch 9/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 129ms/step - loss: 2.6148 - sparse_categorical_accuracy: 0.1005 - val_loss: 2.5675 - val_sparse_categorical_accuracy: 0.1130\n",
            "Epoch 10/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - loss: 2.5815 - sparse_categorical_accuracy: 0.1100 - val_loss: 2.5431 - val_sparse_categorical_accuracy: 0.1130\n",
            "Epoch 11/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.5373 - sparse_categorical_accuracy: 0.1181 - val_loss: 2.5215 - val_sparse_categorical_accuracy: 0.1130\n",
            "Epoch 12/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 129ms/step - loss: 2.5349 - sparse_categorical_accuracy: 0.1111 - val_loss: 2.5020 - val_sparse_categorical_accuracy: 0.1158\n",
            "Epoch 13/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 129ms/step - loss: 2.5178 - sparse_categorical_accuracy: 0.1126 - val_loss: 2.4839 - val_sparse_categorical_accuracy: 0.1192\n",
            "Epoch 14/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 128ms/step - loss: 2.4937 - sparse_categorical_accuracy: 0.1194 - val_loss: 2.4670 - val_sparse_categorical_accuracy: 0.1247\n",
            "Epoch 15/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - loss: 2.4708 - sparse_categorical_accuracy: 0.1290 - val_loss: 2.4508 - val_sparse_categorical_accuracy: 0.1267\n",
            "Epoch 16/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - loss: 2.4645 - sparse_categorical_accuracy: 0.1219 - val_loss: 2.4356 - val_sparse_categorical_accuracy: 0.1301\n",
            "Epoch 17/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 128ms/step - loss: 2.4549 - sparse_categorical_accuracy: 0.1277 - val_loss: 2.4209 - val_sparse_categorical_accuracy: 0.1336\n",
            "Epoch 18/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 129ms/step - loss: 2.4337 - sparse_categorical_accuracy: 0.1341 - val_loss: 2.4069 - val_sparse_categorical_accuracy: 0.1411\n",
            "Epoch 19/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 129ms/step - loss: 2.4190 - sparse_categorical_accuracy: 0.1325 - val_loss: 2.3932 - val_sparse_categorical_accuracy: 0.1466\n",
            "Epoch 20/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 129ms/step - loss: 2.3926 - sparse_categorical_accuracy: 0.1490 - val_loss: 2.3796 - val_sparse_categorical_accuracy: 0.1500\n",
            "Epoch 21/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 129ms/step - loss: 2.3983 - sparse_categorical_accuracy: 0.1446 - val_loss: 2.3667 - val_sparse_categorical_accuracy: 0.1555\n",
            "Epoch 22/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - loss: 2.3926 - sparse_categorical_accuracy: 0.1429 - val_loss: 2.3531 - val_sparse_categorical_accuracy: 0.1603\n",
            "Epoch 23/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 128ms/step - loss: 2.3854 - sparse_categorical_accuracy: 0.1466 - val_loss: 2.3408 - val_sparse_categorical_accuracy: 0.1644\n",
            "Epoch 24/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - loss: 2.3372 - sparse_categorical_accuracy: 0.1566 - val_loss: 2.3288 - val_sparse_categorical_accuracy: 0.1651\n",
            "Epoch 25/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.3507 - sparse_categorical_accuracy: 0.1658 - val_loss: 2.3169 - val_sparse_categorical_accuracy: 0.1726\n",
            "Epoch 26/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 129ms/step - loss: 2.3266 - sparse_categorical_accuracy: 0.1719 - val_loss: 2.3050 - val_sparse_categorical_accuracy: 0.1795\n",
            "Epoch 27/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.3120 - sparse_categorical_accuracy: 0.1711 - val_loss: 2.2937 - val_sparse_categorical_accuracy: 0.1795\n",
            "Epoch 28/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 2.3106 - sparse_categorical_accuracy: 0.1761 - val_loss: 2.2827 - val_sparse_categorical_accuracy: 0.1842\n",
            "Epoch 29/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - loss: 2.2986 - sparse_categorical_accuracy: 0.1716 - val_loss: 2.2721 - val_sparse_categorical_accuracy: 0.1884\n",
            "Epoch 30/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 2.2885 - sparse_categorical_accuracy: 0.1747 - val_loss: 2.2614 - val_sparse_categorical_accuracy: 0.1986\n",
            "Epoch 31/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 2.2755 - sparse_categorical_accuracy: 0.1926 - val_loss: 2.2511 - val_sparse_categorical_accuracy: 0.2000\n",
            "Epoch 32/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 129ms/step - loss: 2.2769 - sparse_categorical_accuracy: 0.1864 - val_loss: 2.2414 - val_sparse_categorical_accuracy: 0.2055\n",
            "Epoch 33/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - loss: 2.2647 - sparse_categorical_accuracy: 0.1991 - val_loss: 2.2322 - val_sparse_categorical_accuracy: 0.2110\n",
            "Epoch 34/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.2437 - sparse_categorical_accuracy: 0.2007 - val_loss: 2.2226 - val_sparse_categorical_accuracy: 0.2110\n",
            "Epoch 35/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.2331 - sparse_categorical_accuracy: 0.2034 - val_loss: 2.2136 - val_sparse_categorical_accuracy: 0.2144\n",
            "Epoch 36/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.2228 - sparse_categorical_accuracy: 0.2071 - val_loss: 2.2050 - val_sparse_categorical_accuracy: 0.2171\n",
            "Epoch 37/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.2129 - sparse_categorical_accuracy: 0.2028 - val_loss: 2.1966 - val_sparse_categorical_accuracy: 0.2205\n",
            "Epoch 38/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 129ms/step - loss: 2.2153 - sparse_categorical_accuracy: 0.2084 - val_loss: 2.1883 - val_sparse_categorical_accuracy: 0.2205\n",
            "Epoch 39/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - loss: 2.2064 - sparse_categorical_accuracy: 0.2088 - val_loss: 2.1803 - val_sparse_categorical_accuracy: 0.2192\n",
            "Epoch 40/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.1974 - sparse_categorical_accuracy: 0.2117 - val_loss: 2.1724 - val_sparse_categorical_accuracy: 0.2158\n",
            "Epoch 41/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 129ms/step - loss: 2.1977 - sparse_categorical_accuracy: 0.2074 - val_loss: 2.1647 - val_sparse_categorical_accuracy: 0.2151\n",
            "Epoch 42/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 130ms/step - loss: 2.1757 - sparse_categorical_accuracy: 0.2284 - val_loss: 2.1577 - val_sparse_categorical_accuracy: 0.2171\n",
            "Epoch 43/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 2.1725 - sparse_categorical_accuracy: 0.2181 - val_loss: 2.1506 - val_sparse_categorical_accuracy: 0.2233\n",
            "Epoch 44/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 2.1686 - sparse_categorical_accuracy: 0.2107 - val_loss: 2.1451 - val_sparse_categorical_accuracy: 0.2137\n",
            "Epoch 45/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - loss: 2.1614 - sparse_categorical_accuracy: 0.2190 - val_loss: 2.1373 - val_sparse_categorical_accuracy: 0.2171\n",
            "Epoch 46/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 129ms/step - loss: 2.1449 - sparse_categorical_accuracy: 0.2142 - val_loss: 2.1317 - val_sparse_categorical_accuracy: 0.2178\n",
            "Epoch 47/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 128ms/step - loss: 2.1328 - sparse_categorical_accuracy: 0.2229 - val_loss: 2.1245 - val_sparse_categorical_accuracy: 0.2212\n",
            "Epoch 48/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - loss: 2.1453 - sparse_categorical_accuracy: 0.2128 - val_loss: 2.1187 - val_sparse_categorical_accuracy: 0.2212\n",
            "Epoch 49/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - loss: 2.1389 - sparse_categorical_accuracy: 0.2076 - val_loss: 2.1134 - val_sparse_categorical_accuracy: 0.2281\n",
            "Epoch 50/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.1350 - sparse_categorical_accuracy: 0.2218 - val_loss: 2.1080 - val_sparse_categorical_accuracy: 0.2377\n",
            "Epoch 51/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 2.1229 - sparse_categorical_accuracy: 0.2245 - val_loss: 2.1020 - val_sparse_categorical_accuracy: 0.2425\n",
            "Epoch 52/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - loss: 2.1283 - sparse_categorical_accuracy: 0.2184 - val_loss: 2.0964 - val_sparse_categorical_accuracy: 0.2315\n",
            "Epoch 53/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 2.1246 - sparse_categorical_accuracy: 0.2263 - val_loss: 2.0915 - val_sparse_categorical_accuracy: 0.2390\n",
            "Epoch 54/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 2.1117 - sparse_categorical_accuracy: 0.2237 - val_loss: 2.0878 - val_sparse_categorical_accuracy: 0.2534\n",
            "Epoch 55/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - loss: 2.1059 - sparse_categorical_accuracy: 0.2233 - val_loss: 2.0818 - val_sparse_categorical_accuracy: 0.2384\n",
            "Epoch 56/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 2.1013 - sparse_categorical_accuracy: 0.2302 - val_loss: 2.0776 - val_sparse_categorical_accuracy: 0.2459\n",
            "Epoch 57/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 2.0973 - sparse_categorical_accuracy: 0.2182 - val_loss: 2.0732 - val_sparse_categorical_accuracy: 0.2521\n",
            "Epoch 58/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 128ms/step - loss: 2.0915 - sparse_categorical_accuracy: 0.2197 - val_loss: 2.0698 - val_sparse_categorical_accuracy: 0.2596\n",
            "Epoch 59/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 128ms/step - loss: 2.1027 - sparse_categorical_accuracy: 0.2166 - val_loss: 2.0655 - val_sparse_categorical_accuracy: 0.2596\n",
            "Epoch 60/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 2.0872 - sparse_categorical_accuracy: 0.2363 - val_loss: 2.0613 - val_sparse_categorical_accuracy: 0.2623\n",
            "Epoch 61/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.0838 - sparse_categorical_accuracy: 0.2224 - val_loss: 2.0575 - val_sparse_categorical_accuracy: 0.2705\n",
            "Epoch 62/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 129ms/step - loss: 2.0737 - sparse_categorical_accuracy: 0.2289 - val_loss: 2.0531 - val_sparse_categorical_accuracy: 0.2644\n",
            "Epoch 63/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 128ms/step - loss: 2.0614 - sparse_categorical_accuracy: 0.2376 - val_loss: 2.0495 - val_sparse_categorical_accuracy: 0.2699\n",
            "Epoch 64/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.0737 - sparse_categorical_accuracy: 0.2312 - val_loss: 2.0463 - val_sparse_categorical_accuracy: 0.2760\n",
            "Epoch 65/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - loss: 2.0659 - sparse_categorical_accuracy: 0.2213 - val_loss: 2.0429 - val_sparse_categorical_accuracy: 0.2733\n",
            "Epoch 66/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 129ms/step - loss: 2.0572 - sparse_categorical_accuracy: 0.2344 - val_loss: 2.0396 - val_sparse_categorical_accuracy: 0.2753\n",
            "Epoch 67/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.0707 - sparse_categorical_accuracy: 0.2253 - val_loss: 2.0368 - val_sparse_categorical_accuracy: 0.2726\n",
            "Epoch 68/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 129ms/step - loss: 2.0548 - sparse_categorical_accuracy: 0.2379 - val_loss: 2.0338 - val_sparse_categorical_accuracy: 0.2767\n",
            "Epoch 69/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - loss: 2.0377 - sparse_categorical_accuracy: 0.2351 - val_loss: 2.0301 - val_sparse_categorical_accuracy: 0.2808\n",
            "Epoch 70/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 2.0460 - sparse_categorical_accuracy: 0.2434 - val_loss: 2.0268 - val_sparse_categorical_accuracy: 0.2795\n",
            "Epoch 71/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 130ms/step - loss: 2.0564 - sparse_categorical_accuracy: 0.2311 - val_loss: 2.0245 - val_sparse_categorical_accuracy: 0.2801\n",
            "Epoch 72/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.0376 - sparse_categorical_accuracy: 0.2293 - val_loss: 2.0211 - val_sparse_categorical_accuracy: 0.2808\n",
            "Epoch 73/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - loss: 2.0476 - sparse_categorical_accuracy: 0.2205 - val_loss: 2.0182 - val_sparse_categorical_accuracy: 0.2836\n",
            "Epoch 74/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.0428 - sparse_categorical_accuracy: 0.2352 - val_loss: 2.0155 - val_sparse_categorical_accuracy: 0.2849\n",
            "Epoch 75/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - loss: 2.0348 - sparse_categorical_accuracy: 0.2312 - val_loss: 2.0126 - val_sparse_categorical_accuracy: 0.2808\n",
            "Epoch 76/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.0344 - sparse_categorical_accuracy: 0.2430 - val_loss: 2.0106 - val_sparse_categorical_accuracy: 0.2795\n",
            "Epoch 77/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 2.0353 - sparse_categorical_accuracy: 0.2345 - val_loss: 2.0082 - val_sparse_categorical_accuracy: 0.2808\n",
            "Epoch 78/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 2.0222 - sparse_categorical_accuracy: 0.2343 - val_loss: 2.0063 - val_sparse_categorical_accuracy: 0.2822\n",
            "Epoch 79/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 129ms/step - loss: 2.0414 - sparse_categorical_accuracy: 0.2313 - val_loss: 2.0035 - val_sparse_categorical_accuracy: 0.2822\n",
            "Epoch 80/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 128ms/step - loss: 2.0143 - sparse_categorical_accuracy: 0.2526 - val_loss: 2.0009 - val_sparse_categorical_accuracy: 0.2836\n",
            "Epoch 81/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - loss: 2.0282 - sparse_categorical_accuracy: 0.2389 - val_loss: 1.9987 - val_sparse_categorical_accuracy: 0.2815\n",
            "Epoch 82/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 124ms/step - loss: 2.0186 - sparse_categorical_accuracy: 0.2412 - val_loss: 1.9970 - val_sparse_categorical_accuracy: 0.2842\n",
            "Epoch 83/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.0149 - sparse_categorical_accuracy: 0.2386 - val_loss: 1.9948 - val_sparse_categorical_accuracy: 0.2836\n",
            "Epoch 84/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 128ms/step - loss: 2.0153 - sparse_categorical_accuracy: 0.2439 - val_loss: 1.9919 - val_sparse_categorical_accuracy: 0.2890\n",
            "Epoch 85/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.0083 - sparse_categorical_accuracy: 0.2412 - val_loss: 1.9900 - val_sparse_categorical_accuracy: 0.2856\n",
            "Epoch 86/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - loss: 2.0049 - sparse_categorical_accuracy: 0.2422 - val_loss: 1.9876 - val_sparse_categorical_accuracy: 0.2829\n",
            "Epoch 87/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 2.0081 - sparse_categorical_accuracy: 0.2276 - val_loss: 1.9860 - val_sparse_categorical_accuracy: 0.2836\n",
            "Epoch 88/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 2.0162 - sparse_categorical_accuracy: 0.2393 - val_loss: 1.9841 - val_sparse_categorical_accuracy: 0.2856\n",
            "Epoch 89/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 1.9967 - sparse_categorical_accuracy: 0.2569 - val_loss: 1.9815 - val_sparse_categorical_accuracy: 0.2829\n",
            "Epoch 90/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 2.0017 - sparse_categorical_accuracy: 0.2464 - val_loss: 1.9811 - val_sparse_categorical_accuracy: 0.2822\n",
            "Epoch 91/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - loss: 2.0102 - sparse_categorical_accuracy: 0.2427 - val_loss: 1.9783 - val_sparse_categorical_accuracy: 0.2829\n",
            "Epoch 92/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.0001 - sparse_categorical_accuracy: 0.2364 - val_loss: 1.9774 - val_sparse_categorical_accuracy: 0.2829\n",
            "Epoch 93/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 1.9830 - sparse_categorical_accuracy: 0.2531 - val_loss: 1.9751 - val_sparse_categorical_accuracy: 0.2849\n",
            "Epoch 94/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 1.9918 - sparse_categorical_accuracy: 0.2374 - val_loss: 1.9728 - val_sparse_categorical_accuracy: 0.2836\n",
            "Epoch 95/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 1.9969 - sparse_categorical_accuracy: 0.2397 - val_loss: 1.9716 - val_sparse_categorical_accuracy: 0.2801\n",
            "Epoch 96/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 129ms/step - loss: 1.9846 - sparse_categorical_accuracy: 0.2388 - val_loss: 1.9700 - val_sparse_categorical_accuracy: 0.2863\n",
            "Epoch 97/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - loss: 1.9814 - sparse_categorical_accuracy: 0.2445 - val_loss: 1.9680 - val_sparse_categorical_accuracy: 0.2897\n",
            "Epoch 98/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 1.9887 - sparse_categorical_accuracy: 0.2431 - val_loss: 1.9668 - val_sparse_categorical_accuracy: 0.2863\n",
            "Epoch 99/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 128ms/step - loss: 1.9703 - sparse_categorical_accuracy: 0.2539 - val_loss: 1.9657 - val_sparse_categorical_accuracy: 0.2829\n",
            "Epoch 100/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 1.9860 - sparse_categorical_accuracy: 0.2422 - val_loss: 1.9639 - val_sparse_categorical_accuracy: 0.2788\n",
            "Epoch 101/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 1.9701 - sparse_categorical_accuracy: 0.2526 - val_loss: 1.9621 - val_sparse_categorical_accuracy: 0.2788\n",
            "Epoch 102/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 129ms/step - loss: 1.9731 - sparse_categorical_accuracy: 0.2543 - val_loss: 1.9602 - val_sparse_categorical_accuracy: 0.2904\n",
            "Epoch 103/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 130ms/step - loss: 1.9736 - sparse_categorical_accuracy: 0.2471 - val_loss: 1.9587 - val_sparse_categorical_accuracy: 0.2897\n",
            "Epoch 104/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - loss: 1.9733 - sparse_categorical_accuracy: 0.2522 - val_loss: 1.9584 - val_sparse_categorical_accuracy: 0.2774\n",
            "Epoch 105/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - loss: 1.9766 - sparse_categorical_accuracy: 0.2402 - val_loss: 1.9568 - val_sparse_categorical_accuracy: 0.2822\n",
            "Epoch 106/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 1.9647 - sparse_categorical_accuracy: 0.2597 - val_loss: 1.9563 - val_sparse_categorical_accuracy: 0.2781\n",
            "Epoch 107/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 129ms/step - loss: 1.9688 - sparse_categorical_accuracy: 0.2490 - val_loss: 1.9539 - val_sparse_categorical_accuracy: 0.2815\n",
            "Epoch 108/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 1.9716 - sparse_categorical_accuracy: 0.2542 - val_loss: 1.9522 - val_sparse_categorical_accuracy: 0.2911\n",
            "Epoch 109/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 1.9771 - sparse_categorical_accuracy: 0.2560 - val_loss: 1.9511 - val_sparse_categorical_accuracy: 0.2801\n",
            "Epoch 110/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - loss: 1.9770 - sparse_categorical_accuracy: 0.2521 - val_loss: 1.9504 - val_sparse_categorical_accuracy: 0.2795\n",
            "Epoch 111/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 1.9658 - sparse_categorical_accuracy: 0.2587 - val_loss: 1.9486 - val_sparse_categorical_accuracy: 0.2897\n",
            "Epoch 112/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - loss: 1.9705 - sparse_categorical_accuracy: 0.2496 - val_loss: 1.9477 - val_sparse_categorical_accuracy: 0.2829\n",
            "Epoch 113/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 1.9637 - sparse_categorical_accuracy: 0.2497 - val_loss: 1.9472 - val_sparse_categorical_accuracy: 0.2815\n",
            "Epoch 114/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 1.9552 - sparse_categorical_accuracy: 0.2509 - val_loss: 1.9449 - val_sparse_categorical_accuracy: 0.2890\n",
            "Epoch 115/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - loss: 1.9838 - sparse_categorical_accuracy: 0.2285 - val_loss: 1.9439 - val_sparse_categorical_accuracy: 0.2836\n",
            "Epoch 116/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 1.9456 - sparse_categorical_accuracy: 0.2594 - val_loss: 1.9439 - val_sparse_categorical_accuracy: 0.2753\n",
            "Epoch 117/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 1.9502 - sparse_categorical_accuracy: 0.2544 - val_loss: 1.9419 - val_sparse_categorical_accuracy: 0.2767\n",
            "Epoch 118/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - loss: 1.9433 - sparse_categorical_accuracy: 0.2613 - val_loss: 1.9402 - val_sparse_categorical_accuracy: 0.2842\n",
            "Epoch 119/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 1.9517 - sparse_categorical_accuracy: 0.2585 - val_loss: 1.9395 - val_sparse_categorical_accuracy: 0.2774\n",
            "Epoch 120/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 1.9565 - sparse_categorical_accuracy: 0.2613 - val_loss: 1.9391 - val_sparse_categorical_accuracy: 0.2747\n",
            "Epoch 121/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 1.9528 - sparse_categorical_accuracy: 0.2520 - val_loss: 1.9372 - val_sparse_categorical_accuracy: 0.2815\n",
            "Epoch 122/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 1.9496 - sparse_categorical_accuracy: 0.2582 - val_loss: 1.9368 - val_sparse_categorical_accuracy: 0.2767\n",
            "Epoch 123/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 1.9488 - sparse_categorical_accuracy: 0.2608 - val_loss: 1.9350 - val_sparse_categorical_accuracy: 0.2760\n",
            "Epoch 124/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 1.9677 - sparse_categorical_accuracy: 0.2405 - val_loss: 1.9344 - val_sparse_categorical_accuracy: 0.2767\n",
            "Epoch 125/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 1.9718 - sparse_categorical_accuracy: 0.2379 - val_loss: 1.9331 - val_sparse_categorical_accuracy: 0.2836\n",
            "Epoch 126/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 1.9386 - sparse_categorical_accuracy: 0.2636 - val_loss: 1.9323 - val_sparse_categorical_accuracy: 0.2788\n",
            "Epoch 127/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 1.9396 - sparse_categorical_accuracy: 0.2712 - val_loss: 1.9313 - val_sparse_categorical_accuracy: 0.2774\n",
            "Epoch 128/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 1.9482 - sparse_categorical_accuracy: 0.2506 - val_loss: 1.9303 - val_sparse_categorical_accuracy: 0.2774\n",
            "Epoch 129/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 1.9575 - sparse_categorical_accuracy: 0.2643 - val_loss: 1.9290 - val_sparse_categorical_accuracy: 0.2829\n",
            "Epoch 130/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 1.9424 - sparse_categorical_accuracy: 0.2568 - val_loss: 1.9291 - val_sparse_categorical_accuracy: 0.2815\n",
            "Epoch 131/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 1.9384 - sparse_categorical_accuracy: 0.2638 - val_loss: 1.9275 - val_sparse_categorical_accuracy: 0.2822\n",
            "Epoch 132/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - loss: 1.9569 - sparse_categorical_accuracy: 0.2609 - val_loss: 1.9264 - val_sparse_categorical_accuracy: 0.2801\n",
            "Epoch 133/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 1.9416 - sparse_categorical_accuracy: 0.2614 - val_loss: 1.9256 - val_sparse_categorical_accuracy: 0.2781\n",
            "Epoch 134/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 1.9324 - sparse_categorical_accuracy: 0.2684 - val_loss: 1.9256 - val_sparse_categorical_accuracy: 0.2788\n",
            "Epoch 135/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - loss: 1.9422 - sparse_categorical_accuracy: 0.2600 - val_loss: 1.9238 - val_sparse_categorical_accuracy: 0.2795\n",
            "Epoch 136/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - loss: 1.9355 - sparse_categorical_accuracy: 0.2515 - val_loss: 1.9232 - val_sparse_categorical_accuracy: 0.2822\n",
            "Epoch 137/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 1.9187 - sparse_categorical_accuracy: 0.2584 - val_loss: 1.9225 - val_sparse_categorical_accuracy: 0.2815\n",
            "Epoch 138/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 1.9262 - sparse_categorical_accuracy: 0.2617 - val_loss: 1.9210 - val_sparse_categorical_accuracy: 0.2842\n",
            "Epoch 139/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 1.9388 - sparse_categorical_accuracy: 0.2605 - val_loss: 1.9207 - val_sparse_categorical_accuracy: 0.2781\n",
            "Epoch 140/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 1.9199 - sparse_categorical_accuracy: 0.2528 - val_loss: 1.9201 - val_sparse_categorical_accuracy: 0.2822\n",
            "Epoch 141/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 1.9276 - sparse_categorical_accuracy: 0.2635 - val_loss: 1.9190 - val_sparse_categorical_accuracy: 0.2801\n",
            "Epoch 142/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - loss: 1.9445 - sparse_categorical_accuracy: 0.2516 - val_loss: 1.9193 - val_sparse_categorical_accuracy: 0.2842\n",
            "Epoch 143/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 1.9256 - sparse_categorical_accuracy: 0.2629 - val_loss: 1.9175 - val_sparse_categorical_accuracy: 0.2836\n",
            "Epoch 144/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 1.9436 - sparse_categorical_accuracy: 0.2525 - val_loss: 1.9171 - val_sparse_categorical_accuracy: 0.2856\n",
            "Epoch 145/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 1.9086 - sparse_categorical_accuracy: 0.2604 - val_loss: 1.9169 - val_sparse_categorical_accuracy: 0.2842\n",
            "Epoch 146/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 1.9299 - sparse_categorical_accuracy: 0.2633 - val_loss: 1.9152 - val_sparse_categorical_accuracy: 0.2822\n",
            "Epoch 147/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - loss: 1.9266 - sparse_categorical_accuracy: 0.2563 - val_loss: 1.9156 - val_sparse_categorical_accuracy: 0.2815\n",
            "Epoch 148/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 1.9477 - sparse_categorical_accuracy: 0.2537 - val_loss: 1.9141 - val_sparse_categorical_accuracy: 0.2849\n",
            "Epoch 149/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 1.9353 - sparse_categorical_accuracy: 0.2469 - val_loss: 1.9124 - val_sparse_categorical_accuracy: 0.2897\n",
            "Epoch 150/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 129ms/step - loss: 1.9249 - sparse_categorical_accuracy: 0.2520 - val_loss: 1.9133 - val_sparse_categorical_accuracy: 0.2829\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 1.9071 - sparse_categorical_accuracy: 0.2935\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8764809370040894, 0.29879385232925415]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}